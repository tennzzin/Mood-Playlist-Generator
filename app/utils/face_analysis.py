from deepface import DeepFace

# Detect dominant facial emotion from uploaded image
def analyze_face_mood(image):
    try:
        analysis = DeepFace.analyze(image, actions=["emotion"])
        emotion = analysis[0]["dominant_emotion"]

        # Mapping DeepFace emotions to moods used in playlist logic
        mood_mapping = {
            "happy": "happy ðŸ˜Š",
            "sad": "sad ðŸ˜ž",
            "angry": "angry ðŸ˜¡",
            "fear": "nervous ðŸ˜¨",
            "surprise": "surprised ðŸ˜²",
            "disgust": "disgusted ðŸ¤¢",
            "neutral": "neutral/relaxed ðŸ˜Œ"
        }
        return mood_mapping.get(emotion, "unknown ðŸ¤”")
    
    except Exception as e:
        return f"Error analyzing: {str(e)}"